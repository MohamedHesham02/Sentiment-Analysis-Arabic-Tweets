{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedHesham02/Sentiment-Analysis-Arabic-Tweets/blob/main/sentiment_analysis_model_deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j4WQZ1q4UFH",
        "outputId": "011e918f-8b6f-4627-bead-0d6ae08d5708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colabcode in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pyngrok>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from colabcode) (5.1.0)\n",
            "Requirement already satisfied: jupyterlab==3.0.7 in /usr/local/lib/python3.7/dist-packages (from colabcode) (3.0.7)\n",
            "Requirement already satisfied: uvicorn==0.13.1 in /usr/local/lib/python3.7/dist-packages (from colabcode) (0.13.1)\n",
            "Requirement already satisfied: nest-asyncio==1.4.3 in /usr/local/lib/python3.7/dist-packages (from colabcode) (1.4.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (6.1)\n",
            "Requirement already satisfied: jupyterlab-server~=2.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.10.3)\n",
            "Requirement already satisfied: nbclassic~=0.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (0.3.6)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Requirement already satisfied: jupyter-server~=1.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (1.15.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (21.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (0.13.0)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (3.10.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.1.12)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (22.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.1)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.2.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.5.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.3.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.2)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.9.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.4)\n",
            "Requirement already satisfied: json5 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.9.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.11.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.7.0)\n",
            "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.1.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.21)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2018.9)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2021.10.8)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.75.0)\n",
            "Requirement already satisfied: starlette==0.17.1 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.17.1)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.9.0)\n",
            "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi) (3.10.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi\n",
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiFZaUZvFpMk",
        "outputId": "f9ce2618-7e73-4f5c-d873-3560e950f173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sklearn \n",
        "import requests, json\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "import pickle\n",
        "import joblib\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_qTCTZO6MVc",
        "outputId": "424be48d-bead-43cb-9aa8-f9de2f439f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ونسيتي انه من الجماعه الاحمديه او القاديانيه..واللي بيؤمنوا بوجود رسول بعد النبي محمد اسمه ميرزا غلام احمد.. https://t.co/PHJqDvKrER\n"
          ]
        }
      ],
      "source": [
        "url = 'https://recruitment.aimtechnologies.co/ai-tasks'\n",
        "id = 1168104257578573824\n",
        "id_formalization = [str(id)]\n",
        "request_content = requests.post( url, data=json.dumps(id_formalization)).content\n",
        "out = json.loads(request_content)\n",
        "tweet = out[str(id)]\n",
        "print(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OcYdXyNwKBxz"
      },
      "outputs": [],
      "source": [
        "# Arabic letters encodings\n",
        "\n",
        "COMMA = u'\\u060C'\n",
        "SEMICOLON = u'\\u061B'\n",
        "QUESTION = u'\\u061F'\n",
        "HAMZA = u'\\u0621'\n",
        "ALEF_MADDA = u'\\u0622'\n",
        "ALEF_HAMZA_ABOVE = u'\\u0623'\n",
        "WAW_HAMZA = u'\\u0624'\n",
        "ALEF_HAMZA_BELOW = u'\\u0625'\n",
        "YEH_HAMZA = u'\\u0626'\n",
        "ALEF = u'\\u0627'\n",
        "TEH_MARBUTA = u'\\u0629'\n",
        "TATWEEL = u'\\u0640'\n",
        "LAM = u'\\u0644'\n",
        "HEH = u'\\u0647'\n",
        "YEH = u'\\u064a'\n",
        "ALEF_MAKSURA = u'\\u0649'\n",
        "HAMZA_ABOVE = u'\\u0654'\n",
        "HAMZA_BELOW = u'\\u0655'\n",
        "PERCENT = u'\\u066a'\n",
        "DECIMAL = u'\\u066b'\n",
        "THOUSANDS = u'\\u066c'\n",
        "STAR = u'\\u066d'\n",
        "FULL_STOP = u'\\u06d4'\n",
        "BYTE_ORDER_MARK = u'\\ufeff'\n",
        "MULITIPLICATION_SIGN = u'\\u00D7'\n",
        "DIVISION_SIGN = u'\\u00F7'\n",
        "\n",
        "\n",
        "# Tashkeel\n",
        "FATHATAN = u'\\u064b'\n",
        "DAMMATAN = u'\\u064c'\n",
        "KASRATAN = u'\\u064d'\n",
        "FATHA = u'\\u064e'\n",
        "DAMMA = u'\\u064f'\n",
        "KASRA = u'\\u0650'\n",
        "SHADDA = u'\\u0651'\n",
        "SUKUN = u'\\u0652'\n",
        "\n",
        "#Ligatures\n",
        "LAM_ALEF = u'\\ufefb'\n",
        "LAM_ALEF_HAMZA_ABOVE = u'\\ufef7'\n",
        "LAM_ALEF_HAMZA_BELOW = u'\\ufef9'\n",
        "LAM_ALEF_MADDA_ABOVE = u'\\ufef5'\n",
        "\n",
        "HARAKAT_PAT = re.compile(u\"[\"+u\"\".join([FATHATAN, DAMMATAN, KASRATAN, FATHA, DAMMA, KASRA, SUKUN, SHADDA])+u\"]\")\n",
        "HAMZAT_PAT = re.compile(u\"[\"+u\"\".join([WAW_HAMZA, YEH_HAMZA])+u\"]\")\n",
        "ALEFAT_PAT = re.compile(u\"[\"+u\"\".join([ALEF_MADDA, ALEF_HAMZA_ABOVE, ALEF_HAMZA_BELOW, HAMZA_ABOVE, HAMZA_BELOW])+u\"]\")\n",
        "LAMALEFAT_PAT = re.compile(u\"[\"+u\"\".join([LAM_ALEF, LAM_ALEF_HAMZA_ABOVE, LAM_ALEF_HAMZA_BELOW, LAM_ALEF_MADDA_ABOVE])+u\"]\")\n",
        "\n",
        "WESTERN_ARABIC_NUMERALS = ['0','1','2','3','4','5','6','7','8','9']\n",
        "EASTERN_ARABIC_NUMERALS = [u'\\u06F0', u'\\u06F1', u'\\u06F2', u'\\u06F3', u'\\u0664', u'\\u06F5', u'\\u0666', u'\\u06F7', u'\\u06F8', u'\\u06F9']\n",
        "\n",
        "eastern_to_western_numerals = {}\n",
        "for i in range(len(EASTERN_ARABIC_NUMERALS)):\n",
        "    eastern_to_western_numerals[EASTERN_ARABIC_NUMERALS[i]] = WESTERN_ARABIC_NUMERALS[i]\n",
        "\n",
        "arabic_punctuations = COMMA + SEMICOLON + QUESTION + PERCENT + DECIMAL + THOUSANDS + STAR + FULL_STOP + MULITIPLICATION_SIGN + DIVISION_SIGN\n",
        "all_punctuations = string.punctuation + arabic_punctuations + '()[]{}' # English & Arabic punctuations\n",
        "\n",
        "all_punctuations = ''.join(list(set(all_punctuations)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FnrKhw7mOV8R"
      },
      "outputs": [],
      "source": [
        "def strip_tashkeel(text):\n",
        "    text = HARAKAT_PAT.sub('', text)\n",
        "    return text \n",
        "\n",
        "def strip_tatweel(text):\n",
        "    return re.sub(u'[%s]' % TATWEEL, '', text)\n",
        "\n",
        "def remove_non_arabic(text):\n",
        "    return ' '.join(re.sub(u\"[^\\u0621-\\u063A\\u0640-\\u0652 ]\", \" \", text,  flags=re.UNICODE).split())\n",
        "\n",
        "def keep_arabic_english_n_symbols(text):\n",
        "    return ' '.join(re.sub(u\"[^\\u0621-\\u063A\\u0640-\\u064aa-zA-Z#@_:/ ]\", \"\", text,  flags=re.UNICODE).split())\n",
        "\n",
        "def normalize_hamza(text):\n",
        "    text = ALEFAT_PAT.sub(ALEF, text)\n",
        "    text = HAMZAT_PAT.sub(HAMZA, text)\n",
        "    return text\n",
        "\n",
        "def normalize_lamalef(text): \n",
        "    text = LAMALEFAT_PAT.sub((LAM, ALEF), text)\n",
        "    return text\n",
        "\n",
        "def normalize_spellerrors(text):\n",
        "    text = re.sub(u'[%s]' % TEH_MARBUTA, HEH, text)\n",
        "    return re.sub(u'[%s]' % ALEF_MAKSURA, YEH, text)\n",
        "\n",
        "def remove_underscore(text):\n",
        "    return ' '.join(text.split('_'))\n",
        "\n",
        "def remove_retweet_tag(text):\n",
        "    tag = re.compile('rt @[a-zA-Z0-9_]+:|@[a-zA-Z0-9_]+')\n",
        "    text = tag.sub('', text)\n",
        "    hashtag = re.compile('\\#')\n",
        "    text = hashtag.sub('', text)\n",
        "    return text\n",
        "\n",
        "def replace_emails(text):\n",
        "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "    for email in emails:\n",
        "        text = text.replace(email,'#')\n",
        "    return text\n",
        "\n",
        "def replace_urls(text):\n",
        "    return re.sub(r\"http\\S+|www.\\S+\", \"#\", text)\n",
        "\n",
        "def convert_eastern_to_western_numerals(text):\n",
        "    for num in EASTERN_ARABIC_NUMERALS:\n",
        "        text = text.replace(num, eastern_to_western_numerals[num])\n",
        "    return text\n",
        "\n",
        "def remove_all_punctuations(text):\n",
        "    for punctuation in all_punctuations:\n",
        "        text = text.replace(punctuation, ' ')\n",
        "    return text\n",
        "\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub('', text)\n",
        "    return text\n",
        "\n",
        "def replace_phone_numbers(text):\n",
        "    return re.sub(r'\\d{10}', '#', text)\n",
        "\n",
        "def remove_extra_spaces(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def normalize_tweet(text):\n",
        "    new_text = text.lower()\n",
        "    new_text = normalize_hamza(new_text)\n",
        "    new_text = strip_tashkeel(new_text)\n",
        "    new_text = strip_tatweel(new_text)\n",
        "    new_text = normalize_spellerrors(new_text)\n",
        "    new_text = remove_retweet_tag(new_text)\n",
        "    new_text = replace_emails(new_text)\n",
        "    new_text = remove_underscore(new_text)\n",
        "    new_text = replace_phone_numbers(new_text)\n",
        "    new_text = remove_all_punctuations(new_text)\n",
        "    new_text = replace_urls(new_text)\n",
        "    new_text = convert_eastern_to_western_numerals(new_text)\n",
        "    new_text = keep_arabic_english_n_symbols(new_text)\n",
        "    new_text = remove_non_arabic(new_text)\n",
        "    new_text = remove_extra_spaces(new_text)\n",
        "    \n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nEgb7O2YRkhE"
      },
      "outputs": [],
      "source": [
        "tweet = normalize_tweet(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qVE_fCX60bzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16864a14-c759-4d3a-dc0e-a2c3f705414d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ونس انه من جمع حمد او قاديانيه ولل يءم وجد رسل بعد نبي حمد اسم يرز غلم حمد\n",
            "  (0, 9584)\t0.30171005846322607\n",
            "  (0, 9178)\t0.39023936849983903\n",
            "  (0, 9008)\t0.22261082392275838\n",
            "  (0, 8828)\t0.14859920879248614\n",
            "  (0, 8473)\t0.21509687543275444\n",
            "  (0, 7481)\t0.2708471910193225\n",
            "  (0, 7242)\t0.10657057577183937\n",
            "  (0, 4690)\t0.39023936849983903\n",
            "  (0, 2781)\t0.2537080171110839\n",
            "  (0, 1971)\t0.40772083226500533\n",
            "  (0, 1592)\t0.17868393822023684\n",
            "  (0, 793)\t0.16055050772703905\n",
            "  (0, 495)\t0.18738566198075468\n",
            "  (0, 478)\t0.17855710484790785\n",
            "  (0, 239)\t0.2155773103457617\n"
          ]
        }
      ],
      "source": [
        "stop = stopwords.words('arabic')\n",
        "arab_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
        "arab_stopwords = '|'.join(arab_stopwords)\n",
        "tweet=tweet.replace(arab_stopwords, '')\n",
        "\n",
        "token = word_tokenize(tweet)\n",
        "string = []\n",
        "st = ISRIStemmer()\n",
        "\n",
        "for i in token:\n",
        "    stemmed = st.stem(i)\n",
        "    string.append(stemmed)\n",
        "    tweet = ' '.join(string)\n",
        "print(tweet)\n",
        "\n",
        "vectorizer = joblib.load(\"/content/vectorizer_feature.pkl\")\n",
        "vector = vectorizer.transform([tweet])\n",
        "\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AfU_IeC-Jpb-"
      },
      "outputs": [],
      "source": [
        "app = FastAPI(title=\"ML Models as API on Google Colab\", description=\"with FastAPI and ColabCode\", version=\"1.0\")\n",
        "\n",
        "model = joblib.load('/content/finalized_model.sav')\n",
        "\n",
        "@app.post(\"/api\", tags=[\"prediction\"])\n",
        "async def get_predictions(tweet:str):\n",
        "  \n",
        "  tweet = normalize_tweet(tweet)\n",
        "  stop = stopwords.words('arabic')\n",
        "  arab_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
        "  arab_stopwords = '|'.join(arab_stopwords)\n",
        "  tweet=tweet.replace(arab_stopwords, '')\n",
        "\n",
        "  token = word_tokenize(tweet)\n",
        "  string = []\n",
        "  st = ISRIStemmer()\n",
        "\n",
        "  for i in token:\n",
        "      stemmed = st.stem(i)\n",
        "      string.append(stemmed)\n",
        "      tweet = ' '.join(string)\n",
        "\n",
        "  vectorizer = joblib.load(\"/content/vectorizer_feature.pkl\")\n",
        "  vector = vectorizer.transform([tweet])\n",
        "\n",
        "  dialects = {\n",
        "      0: 'SA',\n",
        "      1: 'DZ',\n",
        "      2: 'AE',\n",
        "      3: 'BH',\n",
        "      4: 'JO',\n",
        "      5: 'YE',\n",
        "      6: 'OM',\n",
        "      7: 'MA',\n",
        "      8: 'LY',\n",
        "      9: 'IQ',\n",
        "      10: 'PL',\n",
        "      11: 'LB',\n",
        "      12: 'SY',\n",
        "      13: 'SD',\n",
        "      14: 'EG',\n",
        "      15: 'QA',\n",
        "      16: 'TN',\n",
        "      17: 'KW'\n",
        "  }\n",
        "\n",
        "  prediction = model.predict(vector)[0]\n",
        "  dialect_class = dialects[prediction]\n",
        "  return \"This tweet is for class: \", dialect_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp78-_tLANRQ",
        "outputId": "813f5e89-ed8e-483a-dbb5-493fdf2a3056"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [1615]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://1597-35-231-207-149.ngrok.io\" -> \"http://localhost:12000\"\n",
            "INFO:     45.243.211.219:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     45.243.211.219:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     45.243.211.219:0 - \"GET /docs HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "cc = ColabCode(port=12000, code=False)\n",
        "cc.run_app(app=app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLrYQXtJWN1Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sentiment_analysis_model_deployment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}