{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedHesham02/Sentiment-Analysis-Arabic-Tweets/blob/main/sentiment_analysis_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmayBW5nt7Mm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, LSTM,Embedding\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D ,Dropout\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tri-Grams"
      ],
      "metadata": {
        "id": "5-ZevkeBoCrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigrams_features = pd.read_csv('trigrams_features.csv')  \n",
        "labels = pd.read_csv('labels.csv')"
      ],
      "metadata": {
        "id": "rNwLfDZXuPwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del trigrams_features['Unnamed: 0']\n",
        "del labels['Unnamed: 0']"
      ],
      "metadata": {
        "id": "4SL_7gOB0eCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(trigrams_features, labels,test_size=0.2)\n",
        "print('Training Data:', X_train.shape[0])\n",
        "print('Test Data:', X_test.shape[0])"
      ],
      "metadata": {
        "id": "-T9I6uGMveH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4952871d-8cf4-4194-a330-bf0ed14ef33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: 16666\n",
            "Test Data: 4167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k_am32uLKRh",
        "outputId": "3e7f84ea-d522-4377-a0b6-40b1d3a008f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16666, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_model = Sequential()\n",
        "trigram_model.add(Dense(128, input_shape=((trigrams_features.shape)[1],), activation='tanh'))\n",
        "trigram_model.add(Dropout(0.5))\n",
        "trigram_model.add(Dense(64, activation='tanh'))\n",
        "trigram_model.add(Dropout(0.5))\n",
        "trigram_model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "sgd = SGD(learning_rate=0.001)\n",
        "trigram_model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model \n",
        "hist = trigram_model.fit(X_train, y_train, epochs=40, batch_size=32, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ9M7jfBK8un",
        "outputId": "4d511775-359a-4cf9-9867-65ef14e04e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "417/417 [==============================] - 7s 15ms/step - loss: 2.8786 - accuracy: 0.0845 - val_loss: 2.8689 - val_accuracy: 0.0852\n",
            "Epoch 2/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8665 - accuracy: 0.0857 - val_loss: 2.8632 - val_accuracy: 0.0870\n",
            "Epoch 3/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8633 - accuracy: 0.0872 - val_loss: 2.8605 - val_accuracy: 0.0897\n",
            "Epoch 4/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8631 - accuracy: 0.0872 - val_loss: 2.8587 - val_accuracy: 0.0912\n",
            "Epoch 5/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8592 - accuracy: 0.0909 - val_loss: 2.8566 - val_accuracy: 0.0918\n",
            "Epoch 6/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8567 - accuracy: 0.0923 - val_loss: 2.8552 - val_accuracy: 0.0957\n",
            "Epoch 7/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8541 - accuracy: 0.0947 - val_loss: 2.8539 - val_accuracy: 0.0975\n",
            "Epoch 8/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8539 - accuracy: 0.0949 - val_loss: 2.8520 - val_accuracy: 0.0966\n",
            "Epoch 9/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8507 - accuracy: 0.0959 - val_loss: 2.8497 - val_accuracy: 0.0975\n",
            "Epoch 10/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8491 - accuracy: 0.0963 - val_loss: 2.8482 - val_accuracy: 0.0978\n",
            "Epoch 11/40\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.8476 - accuracy: 0.0968 - val_loss: 2.8466 - val_accuracy: 0.0990\n",
            "Epoch 12/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8442 - accuracy: 0.0977 - val_loss: 2.8445 - val_accuracy: 0.0987\n",
            "Epoch 13/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8423 - accuracy: 0.0990 - val_loss: 2.8427 - val_accuracy: 0.0999\n",
            "Epoch 14/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8394 - accuracy: 0.1004 - val_loss: 2.8406 - val_accuracy: 0.1002\n",
            "Epoch 15/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8378 - accuracy: 0.0992 - val_loss: 2.8390 - val_accuracy: 0.1008\n",
            "Epoch 16/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8362 - accuracy: 0.1008 - val_loss: 2.8367 - val_accuracy: 0.1017\n",
            "Epoch 17/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8325 - accuracy: 0.1020 - val_loss: 2.8348 - val_accuracy: 0.1032\n",
            "Epoch 18/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8305 - accuracy: 0.1037 - val_loss: 2.8331 - val_accuracy: 0.1032\n",
            "Epoch 19/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8291 - accuracy: 0.1037 - val_loss: 2.8321 - val_accuracy: 0.1035\n",
            "Epoch 20/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8259 - accuracy: 0.1052 - val_loss: 2.8304 - val_accuracy: 0.1050\n",
            "Epoch 21/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8245 - accuracy: 0.1073 - val_loss: 2.8283 - val_accuracy: 0.1050\n",
            "Epoch 22/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8215 - accuracy: 0.1060 - val_loss: 2.8266 - val_accuracy: 0.1062\n",
            "Epoch 23/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8197 - accuracy: 0.1080 - val_loss: 2.8244 - val_accuracy: 0.1053\n",
            "Epoch 24/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8182 - accuracy: 0.1079 - val_loss: 2.8226 - val_accuracy: 0.1071\n",
            "Epoch 25/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8145 - accuracy: 0.1099 - val_loss: 2.8212 - val_accuracy: 0.1092\n",
            "Epoch 26/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8124 - accuracy: 0.1099 - val_loss: 2.8196 - val_accuracy: 0.1083\n",
            "Epoch 27/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8104 - accuracy: 0.1096 - val_loss: 2.8174 - val_accuracy: 0.1101\n",
            "Epoch 28/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8074 - accuracy: 0.1128 - val_loss: 2.8157 - val_accuracy: 0.1101\n",
            "Epoch 29/40\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.8050 - accuracy: 0.1135 - val_loss: 2.8134 - val_accuracy: 0.1101\n",
            "Epoch 30/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8024 - accuracy: 0.1148 - val_loss: 2.8120 - val_accuracy: 0.1101\n",
            "Epoch 31/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7986 - accuracy: 0.1156 - val_loss: 2.8100 - val_accuracy: 0.1125\n",
            "Epoch 32/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7966 - accuracy: 0.1181 - val_loss: 2.8083 - val_accuracy: 0.1128\n",
            "Epoch 33/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7947 - accuracy: 0.1195 - val_loss: 2.8065 - val_accuracy: 0.1143\n",
            "Epoch 34/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7912 - accuracy: 0.1191 - val_loss: 2.8047 - val_accuracy: 0.1149\n",
            "Epoch 35/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7880 - accuracy: 0.1215 - val_loss: 2.8028 - val_accuracy: 0.1146\n",
            "Epoch 36/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7873 - accuracy: 0.1233 - val_loss: 2.8012 - val_accuracy: 0.1161\n",
            "Epoch 37/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7829 - accuracy: 0.1226 - val_loss: 2.8003 - val_accuracy: 0.1161\n",
            "Epoch 38/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7806 - accuracy: 0.1211 - val_loss: 2.7983 - val_accuracy: 0.1167\n",
            "Epoch 39/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7770 - accuracy: 0.1245 - val_loss: 2.7970 - val_accuracy: 0.1164\n",
            "Epoch 40/40\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7750 - accuracy: 0.1251 - val_loss: 2.7952 - val_accuracy: 0.1188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=100\n",
        "max_features = 10000\n",
        "output_shape = 32\n",
        "\n",
        "modelrnn=Sequential()\n",
        "modelrnn.add(layers.Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=(X_train.shape)[1]))\n",
        "\n",
        "modelrnn.add(layers.LSTM(output_shape)) \n",
        "modelrnn.add(layers.Dropout(0.5))\n",
        "\n",
        "modelrnn.add(layers.Dense(18, activation='softmax'))\n",
        "modelrnn.compile(loss='sparse_categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "modelrnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6vXbGbJXYcs",
        "outputId": "42f3b16d-3a39-44ec-d21d-30d5e1a34fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10000, 100)        1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                17024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 18)                594       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,017,618\n",
            "Trainable params: 1,017,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=modelrnn.fit(X_train,y_train, epochs=4, batch_size=512, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nSpqfGvYa0m",
        "outputId": "ed0547c7-79de-4711-8e5a-0b7c9d3537b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "svm = LinearSVC(max_iter=300, multi_class='ovr')\n",
        "svm = svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "print('Accuracy : ', svm.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVm62bPdx4-U",
        "outputId": "6bc99ba0-0b15-4760-ca77-203359eaf2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.19126469882409408\n",
            "Precision of all classes:  [0.09619816 0.72222222 0.58536585 0.77083333 0.57142857 0.66666667\n",
            " 0.70967742 0.66666667 0.91150442 0.76470588 0.3        0.38235294\n",
            " 0.64       0.53333333 0.9        0.59090909 0.46376812 0.67391304]\n",
            "Recall of all classes:  [0.93036212 0.14130435 0.09876543 0.14979757 0.02867384 0.16113744\n",
            " 0.19469027 0.092827   0.45175439 0.10441767 0.02739726 0.05579399\n",
            " 0.14159292 0.06425703 0.06976744 0.05416667 0.12851406 0.12350598]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRC = LogisticRegression()\n",
        "LRC = LRC.fit(X_train, y_train)\n",
        "\n",
        "y_pred = LRC.predict(X_test)\n",
        "\n",
        "print('Accuracy : ', LRC.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBdwIoB1zMVP",
        "outputId": "be6628b2-9311-46f6-8e80-ee3badd8b048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.18622510199184064\n",
            "Precision of all classes:  [0.09578107 1.         0.62162162 0.81395349 0.5        0.66\n",
            " 0.72881356 0.67741935 0.91262136 0.78125    0.31578947 0.40625\n",
            " 0.6        0.5483871  1.         0.65       0.41975309 0.75      ]\n",
            "Recall of all classes:  [0.93593315 0.11956522 0.09465021 0.1417004  0.02867384 0.1563981\n",
            " 0.19026549 0.08860759 0.4122807  0.10040161 0.02739726 0.05579399\n",
            " 0.13274336 0.06827309 0.03100775 0.05416667 0.13654618 0.11952191]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-Grams"
      ],
      "metadata": {
        "id": "E9WIZzC0oKO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Bigrams_features = pd.read_csv('bigrams_features.csv')"
      ],
      "metadata": {
        "id": "RPwUzpugVTLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del Bigrams_features['Unnamed: 0']"
      ],
      "metadata": {
        "id": "vd3DqRPDV0m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(Bigrams_features, labels,test_size=0.2)\n",
        "print('Training Data:', X_train.shape[0])\n",
        "print('Test Data:', X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpX2ZkbJV5a-",
        "outputId": "a4382b89-721a-438d-9647-fd728a9f067a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: 16666\n",
            "Test Data: 4167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = Sequential()\n",
        "bigram_model.add(Dense(128, input_shape=((Bigrams_features.shape)[1],), activation='tanh'))\n",
        "bigram_model.add(Dropout(0.5))\n",
        "bigram_model.add(Dense(64, activation='tanh'))\n",
        "bigram_model.add(Dropout(0.5))\n",
        "bigram_model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "# Compile model. Stochastic gradient descent for backpropagation with Nesterov accelerated gradient gives good results for this model \n",
        "sgd = SGD(learning_rate=0.001)\n",
        "bigram_model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model \n",
        "hist = bigram_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxQyk1lPWBSn",
        "outputId": "20b329d5-9e9b-4697-fe9d-636cc76fbfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "417/417 [==============================] - 9s 20ms/step - loss: 2.8886 - accuracy: 0.0669 - val_loss: 2.8853 - val_accuracy: 0.0789\n",
            "Epoch 2/20\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.8836 - accuracy: 0.0749 - val_loss: 2.8809 - val_accuracy: 0.0843\n",
            "Epoch 3/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8809 - accuracy: 0.0734 - val_loss: 2.8774 - val_accuracy: 0.0924\n",
            "Epoch 4/20\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.8780 - accuracy: 0.0806 - val_loss: 2.8743 - val_accuracy: 0.0927\n",
            "Epoch 5/20\n",
            "417/417 [==============================] - 9s 22ms/step - loss: 2.8757 - accuracy: 0.0798 - val_loss: 2.8718 - val_accuracy: 0.0933\n",
            "Epoch 6/20\n",
            "417/417 [==============================] - 8s 20ms/step - loss: 2.8729 - accuracy: 0.0829 - val_loss: 2.8697 - val_accuracy: 0.0939\n",
            "Epoch 7/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8705 - accuracy: 0.0828 - val_loss: 2.8678 - val_accuracy: 0.0939\n",
            "Epoch 8/20\n",
            "417/417 [==============================] - 8s 19ms/step - loss: 2.8702 - accuracy: 0.0819 - val_loss: 2.8662 - val_accuracy: 0.0942\n",
            "Epoch 9/20\n",
            "417/417 [==============================] - 8s 19ms/step - loss: 2.8694 - accuracy: 0.0836 - val_loss: 2.8649 - val_accuracy: 0.0942\n",
            "Epoch 10/20\n",
            "417/417 [==============================] - 7s 16ms/step - loss: 2.8690 - accuracy: 0.0836 - val_loss: 2.8637 - val_accuracy: 0.0945\n",
            "Epoch 11/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8662 - accuracy: 0.0854 - val_loss: 2.8625 - val_accuracy: 0.0945\n",
            "Epoch 12/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8651 - accuracy: 0.0881 - val_loss: 2.8615 - val_accuracy: 0.0948\n",
            "Epoch 13/20\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.8641 - accuracy: 0.0893 - val_loss: 2.8605 - val_accuracy: 0.0957\n",
            "Epoch 14/20\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.8620 - accuracy: 0.0891 - val_loss: 2.8596 - val_accuracy: 0.0960\n",
            "Epoch 15/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8621 - accuracy: 0.0887 - val_loss: 2.8587 - val_accuracy: 0.0963\n",
            "Epoch 16/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8593 - accuracy: 0.0904 - val_loss: 2.8578 - val_accuracy: 0.0966\n",
            "Epoch 17/20\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.8603 - accuracy: 0.0903 - val_loss: 2.8571 - val_accuracy: 0.0966\n",
            "Epoch 18/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8599 - accuracy: 0.0907 - val_loss: 2.8564 - val_accuracy: 0.0966\n",
            "Epoch 19/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8595 - accuracy: 0.0905 - val_loss: 2.8557 - val_accuracy: 0.0966\n",
            "Epoch 20/20\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8596 - accuracy: 0.0927 - val_loss: 2.8551 - val_accuracy: 0.0966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "svm = LinearSVC(max_iter=300, multi_class='ovr')\n",
        "svm = svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "print('Accuracy : ', svm.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52jq9BYc1Yxv",
        "outputId": "c73a546f-915e-4d47-8fc4-2ee724ee677e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.27837772978161746\n",
            "Precision of all classes:  [0.13527851 0.31746032 0.2866242  0.44102564 0.24848485 0.38586957\n",
            " 0.35602094 0.41176471 0.7        0.48344371 0.17857143 0.20218579\n",
            " 0.40697674 0.2189781  0.30882353 0.30769231 0.36507937 0.33108108]\n",
            "Recall of all classes:  [0.5698324  0.22727273 0.17175573 0.32575758 0.17446809 0.31555556\n",
            " 0.32692308 0.31390135 0.51953125 0.3173913  0.10245902 0.1504065\n",
            " 0.28225806 0.12931034 0.175      0.20338983 0.28512397 0.196     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRC = LogisticRegression()\n",
        "LRC = LRC.fit(X_train, y_train)\n",
        "\n",
        "y_pred = LRC.predict(X_test)\n",
        "\n",
        "print('Accuracy : ', LRC.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG-XFh_S1fZ3",
        "outputId": "10e3825d-a680-48f8-b265-30db54053172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.29469642428605713\n",
            "Precision of all classes:  [0.14088557 0.53333333 0.3537415  0.48167539 0.27564103 0.42011834\n",
            " 0.40106952 0.47468354 0.82248521 0.48275862 0.20325203 0.23333333\n",
            " 0.46794872 0.20547945 0.66666667 0.32692308 0.44512195 0.33802817]\n",
            "Recall of all classes:  [0.68435754 0.09090909 0.19847328 0.34848485 0.18297872 0.31555556\n",
            " 0.36057692 0.33632287 0.54296875 0.30434783 0.10245902 0.17073171\n",
            " 0.29435484 0.12931034 0.13333333 0.21610169 0.30165289 0.192     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uni-Grams"
      ],
      "metadata": {
        "id": "GeAg6rp0oQcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram = pd.read_csv('unigrams_features.csv')"
      ],
      "metadata": {
        "id": "r1iY1-IFad31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram.head()"
      ],
      "metadata": {
        "outputId": "eaea3411-1769-4bda-c8cb-583ea773e197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "gYkvCcm6ad33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  ءبر  ءبررر  ءبرررر  ءبش  ءبشو  ءثر  ءخر  ءدب  ءسس  ...  ييز  \\\n",
              "0           0  0.0    0.0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "1           1  0.0    0.0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "2           2  0.0    0.0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "3           3  0.0    0.0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "4           4  0.0    0.0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "\n",
              "   ييس  ييش  ييض  ييغ  ييك  ييم  يين  ييه  ييي  \n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[5 rows x 10001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5aef33d0-b79c-43f9-a7fe-14226a12aa6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ءبر</th>\n",
              "      <th>ءبررر</th>\n",
              "      <th>ءبرررر</th>\n",
              "      <th>ءبش</th>\n",
              "      <th>ءبشو</th>\n",
              "      <th>ءثر</th>\n",
              "      <th>ءخر</th>\n",
              "      <th>ءدب</th>\n",
              "      <th>ءسس</th>\n",
              "      <th>...</th>\n",
              "      <th>ييز</th>\n",
              "      <th>ييس</th>\n",
              "      <th>ييش</th>\n",
              "      <th>ييض</th>\n",
              "      <th>ييغ</th>\n",
              "      <th>ييك</th>\n",
              "      <th>ييم</th>\n",
              "      <th>يين</th>\n",
              "      <th>ييه</th>\n",
              "      <th>ييي</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aef33d0-b79c-43f9-a7fe-14226a12aa6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5aef33d0-b79c-43f9-a7fe-14226a12aa6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5aef33d0-b79c-43f9-a7fe-14226a12aa6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del unigram['Unnamed: 0']"
      ],
      "metadata": {
        "id": "bKiI2LGzad34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(unigram, labels,test_size=0.2)\n",
        "print('Training Data:', X_train.shape[0])\n",
        "print('Test Data:', X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce4b276-c913-426b-ea32-19d86d505ebb",
        "id": "79tVIF0Aad35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: 16666\n",
            "Test Data: 4167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "svm = LinearSVC(max_iter=300, multi_class='ovr')\n",
        "svm = svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "print('Accuracy : ', svm.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97abf378-83f5-45f6-aca9-63d28beb1e0d",
        "id": "Fxr0EaiVad35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.4761219102471802\n",
            "Precision of all classes:  [0.40509915 0.29069767 0.43612335 0.59591837 0.49173554 0.51291513\n",
            " 0.50678733 0.53469388 0.70484581 0.64878049 0.31128405 0.35135135\n",
            " 0.57261411 0.25688073 0.5        0.46017699 0.56273764 0.3744856 ]\n",
            "Recall of all classes:  [0.40056022 0.33783784 0.41949153 0.58634538 0.52654867 0.57916667\n",
            " 0.43921569 0.58482143 0.68376068 0.62149533 0.29739777 0.39224138\n",
            " 0.52873563 0.24669604 0.52272727 0.42622951 0.6090535  0.364     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRC = LogisticRegression()\n",
        "LRC = LRC.fit(X_train, y_train)\n",
        "\n",
        "y_pred = LRC.predict(X_test)\n",
        "\n",
        "print('Accuracy : ', LRC.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOiRtphOhBMU",
        "outputId": "c8f74f9d-599f-4d82-a9e5-ed70194eec68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.5121190304775618\n",
            "Precision of all classes:  [0.40807175 0.47916667 0.42168675 0.63059701 0.51171875 0.57874016\n",
            " 0.53043478 0.53036437 0.77619048 0.6713615  0.36051502 0.39272727\n",
            " 0.62337662 0.28899083 0.62857143 0.48387097 0.63114754 0.42152466]\n",
            "Recall of all classes:  [0.50980392 0.31081081 0.44491525 0.67871486 0.57964602 0.6125\n",
            " 0.47843137 0.58482143 0.6965812  0.6682243  0.31226766 0.46551724\n",
            " 0.55172414 0.27753304 0.5        0.43032787 0.63374486 0.376     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Highest Accuracy Achieved at Unigrams in Machine Learning using Logistic Regression \n",
        "## So, I saved it"
      ],
      "metadata": {
        "id": "fxy7YsS4ieIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n",
        "import joblib\n",
        "filename = 'finalized_model.sav'\n",
        "joblib.dump(LRC, filename)"
      ],
      "metadata": {
        "id": "FwFY_AIT4eLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6942a1-f2b7-4510-eebf-1da9afeb23e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['finalized_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_model = Sequential()\n",
        "unigram_model.add(Dense(128, input_shape=((unigram.shape)[1],), activation='tanh'))\n",
        "unigram_model.add(Dropout(0.5))\n",
        "unigram_model.add(Dense(64, activation='tanh'))\n",
        "unigram_model.add(Dropout(0.5))\n",
        "unigram_model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "sgd = SGD(learning_rate=0.001)\n",
        "unigram_model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model \n",
        "hist = unigram_model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HFijtJNitbc",
        "outputId": "aa2b77d9-bc64-497e-927c-5a611edddb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "417/417 [==============================] - 13s 29ms/step - loss: 2.8940 - accuracy: 0.0597 - val_loss: 2.8815 - val_accuracy: 0.0756\n",
            "Epoch 2/100\n",
            "417/417 [==============================] - 9s 22ms/step - loss: 2.8824 - accuracy: 0.0708 - val_loss: 2.8724 - val_accuracy: 0.0954\n",
            "Epoch 3/100\n",
            "417/417 [==============================] - 7s 16ms/step - loss: 2.8733 - accuracy: 0.0804 - val_loss: 2.8645 - val_accuracy: 0.0978\n",
            "Epoch 4/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.8649 - accuracy: 0.0896 - val_loss: 2.8573 - val_accuracy: 0.1023\n",
            "Epoch 5/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.8575 - accuracy: 0.0875 - val_loss: 2.8506 - val_accuracy: 0.1035\n",
            "Epoch 6/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.8501 - accuracy: 0.0941 - val_loss: 2.8443 - val_accuracy: 0.1071\n",
            "Epoch 7/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8438 - accuracy: 0.0992 - val_loss: 2.8382 - val_accuracy: 0.1107\n",
            "Epoch 8/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8363 - accuracy: 0.1076 - val_loss: 2.8323 - val_accuracy: 0.1143\n",
            "Epoch 9/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.8317 - accuracy: 0.1069 - val_loss: 2.8266 - val_accuracy: 0.1164\n",
            "Epoch 10/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.8256 - accuracy: 0.1123 - val_loss: 2.8211 - val_accuracy: 0.1185\n",
            "Epoch 11/100\n",
            "417/417 [==============================] - 9s 20ms/step - loss: 2.8166 - accuracy: 0.1197 - val_loss: 2.8155 - val_accuracy: 0.1209\n",
            "Epoch 12/100\n",
            "417/417 [==============================] - 7s 18ms/step - loss: 2.8099 - accuracy: 0.1228 - val_loss: 2.8099 - val_accuracy: 0.1233\n",
            "Epoch 13/100\n",
            "417/417 [==============================] - 8s 19ms/step - loss: 2.8058 - accuracy: 0.1277 - val_loss: 2.8045 - val_accuracy: 0.1242\n",
            "Epoch 14/100\n",
            "417/417 [==============================] - 7s 18ms/step - loss: 2.7989 - accuracy: 0.1331 - val_loss: 2.7991 - val_accuracy: 0.1272\n",
            "Epoch 15/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7924 - accuracy: 0.1365 - val_loss: 2.7937 - val_accuracy: 0.1299\n",
            "Epoch 16/100\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.7906 - accuracy: 0.1367 - val_loss: 2.7883 - val_accuracy: 0.1332\n",
            "Epoch 17/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7792 - accuracy: 0.1442 - val_loss: 2.7828 - val_accuracy: 0.1380\n",
            "Epoch 18/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7764 - accuracy: 0.1452 - val_loss: 2.7775 - val_accuracy: 0.1410\n",
            "Epoch 19/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7703 - accuracy: 0.1525 - val_loss: 2.7720 - val_accuracy: 0.1437\n",
            "Epoch 20/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7636 - accuracy: 0.1571 - val_loss: 2.7665 - val_accuracy: 0.1485\n",
            "Epoch 21/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7579 - accuracy: 0.1602 - val_loss: 2.7611 - val_accuracy: 0.1536\n",
            "Epoch 22/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.7502 - accuracy: 0.1679 - val_loss: 2.7555 - val_accuracy: 0.1569\n",
            "Epoch 23/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.7423 - accuracy: 0.1682 - val_loss: 2.7500 - val_accuracy: 0.1626\n",
            "Epoch 24/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7390 - accuracy: 0.1706 - val_loss: 2.7443 - val_accuracy: 0.1677\n",
            "Epoch 25/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.7305 - accuracy: 0.1745 - val_loss: 2.7387 - val_accuracy: 0.1698\n",
            "Epoch 26/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7283 - accuracy: 0.1765 - val_loss: 2.7330 - val_accuracy: 0.1770\n",
            "Epoch 27/100\n",
            "417/417 [==============================] - 6s 15ms/step - loss: 2.7193 - accuracy: 0.1858 - val_loss: 2.7273 - val_accuracy: 0.1821\n",
            "Epoch 28/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.7130 - accuracy: 0.1866 - val_loss: 2.7216 - val_accuracy: 0.1854\n",
            "Epoch 29/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.7060 - accuracy: 0.1922 - val_loss: 2.7158 - val_accuracy: 0.1914\n",
            "Epoch 30/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.7003 - accuracy: 0.1893 - val_loss: 2.7101 - val_accuracy: 0.1953\n",
            "Epoch 31/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6900 - accuracy: 0.1979 - val_loss: 2.7041 - val_accuracy: 0.2007\n",
            "Epoch 32/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6877 - accuracy: 0.2025 - val_loss: 2.6983 - val_accuracy: 0.2019\n",
            "Epoch 33/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.6796 - accuracy: 0.2071 - val_loss: 2.6923 - val_accuracy: 0.2046\n",
            "Epoch 34/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6730 - accuracy: 0.2084 - val_loss: 2.6862 - val_accuracy: 0.2103\n",
            "Epoch 35/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6645 - accuracy: 0.2119 - val_loss: 2.6802 - val_accuracy: 0.2154\n",
            "Epoch 36/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.6593 - accuracy: 0.2132 - val_loss: 2.6743 - val_accuracy: 0.2214\n",
            "Epoch 37/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6550 - accuracy: 0.2156 - val_loss: 2.6682 - val_accuracy: 0.2253\n",
            "Epoch 38/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.6483 - accuracy: 0.2234 - val_loss: 2.6622 - val_accuracy: 0.2316\n",
            "Epoch 39/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.6405 - accuracy: 0.2258 - val_loss: 2.6562 - val_accuracy: 0.2355\n",
            "Epoch 40/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6349 - accuracy: 0.2266 - val_loss: 2.6501 - val_accuracy: 0.2415\n",
            "Epoch 41/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6235 - accuracy: 0.2353 - val_loss: 2.6439 - val_accuracy: 0.2445\n",
            "Epoch 42/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.6196 - accuracy: 0.2385 - val_loss: 2.6377 - val_accuracy: 0.2463\n",
            "Epoch 43/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.6142 - accuracy: 0.2378 - val_loss: 2.6316 - val_accuracy: 0.2504\n",
            "Epoch 44/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.6035 - accuracy: 0.2411 - val_loss: 2.6253 - val_accuracy: 0.2513\n",
            "Epoch 45/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5987 - accuracy: 0.2465 - val_loss: 2.6191 - val_accuracy: 0.2537\n",
            "Epoch 46/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5949 - accuracy: 0.2492 - val_loss: 2.6129 - val_accuracy: 0.2567\n",
            "Epoch 47/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5866 - accuracy: 0.2530 - val_loss: 2.6067 - val_accuracy: 0.2597\n",
            "Epoch 48/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5774 - accuracy: 0.2529 - val_loss: 2.6004 - val_accuracy: 0.2624\n",
            "Epoch 49/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5721 - accuracy: 0.2555 - val_loss: 2.5940 - val_accuracy: 0.2654\n",
            "Epoch 50/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5605 - accuracy: 0.2657 - val_loss: 2.5876 - val_accuracy: 0.2705\n",
            "Epoch 51/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.5584 - accuracy: 0.2655 - val_loss: 2.5813 - val_accuracy: 0.2714\n",
            "Epoch 52/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.5525 - accuracy: 0.2686 - val_loss: 2.5749 - val_accuracy: 0.2735\n",
            "Epoch 53/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5423 - accuracy: 0.2687 - val_loss: 2.5685 - val_accuracy: 0.2798\n",
            "Epoch 54/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.5390 - accuracy: 0.2740 - val_loss: 2.5621 - val_accuracy: 0.2837\n",
            "Epoch 55/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.5322 - accuracy: 0.2719 - val_loss: 2.5556 - val_accuracy: 0.2846\n",
            "Epoch 56/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.5234 - accuracy: 0.2759 - val_loss: 2.5490 - val_accuracy: 0.2861\n",
            "Epoch 57/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.5144 - accuracy: 0.2841 - val_loss: 2.5424 - val_accuracy: 0.2885\n",
            "Epoch 58/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.5070 - accuracy: 0.2877 - val_loss: 2.5358 - val_accuracy: 0.2909\n",
            "Epoch 59/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.5017 - accuracy: 0.2834 - val_loss: 2.5291 - val_accuracy: 0.2903\n",
            "Epoch 60/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4980 - accuracy: 0.2883 - val_loss: 2.5225 - val_accuracy: 0.2924\n",
            "Epoch 61/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4874 - accuracy: 0.2898 - val_loss: 2.5159 - val_accuracy: 0.2942\n",
            "Epoch 62/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.4821 - accuracy: 0.2933 - val_loss: 2.5093 - val_accuracy: 0.2969\n",
            "Epoch 63/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4713 - accuracy: 0.2954 - val_loss: 2.5026 - val_accuracy: 0.2987\n",
            "Epoch 64/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4661 - accuracy: 0.2983 - val_loss: 2.4960 - val_accuracy: 0.3017\n",
            "Epoch 65/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.4603 - accuracy: 0.2985 - val_loss: 2.4891 - val_accuracy: 0.3026\n",
            "Epoch 66/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4494 - accuracy: 0.3077 - val_loss: 2.4825 - val_accuracy: 0.3065\n",
            "Epoch 67/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4430 - accuracy: 0.3040 - val_loss: 2.4757 - val_accuracy: 0.3083\n",
            "Epoch 68/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4359 - accuracy: 0.3129 - val_loss: 2.4688 - val_accuracy: 0.3110\n",
            "Epoch 69/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.4336 - accuracy: 0.3136 - val_loss: 2.4620 - val_accuracy: 0.3131\n",
            "Epoch 70/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4193 - accuracy: 0.3197 - val_loss: 2.4551 - val_accuracy: 0.3152\n",
            "Epoch 71/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4165 - accuracy: 0.3158 - val_loss: 2.4482 - val_accuracy: 0.3179\n",
            "Epoch 72/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.4086 - accuracy: 0.3193 - val_loss: 2.4414 - val_accuracy: 0.3197\n",
            "Epoch 73/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.3959 - accuracy: 0.3276 - val_loss: 2.4346 - val_accuracy: 0.3218\n",
            "Epoch 74/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3936 - accuracy: 0.3263 - val_loss: 2.4278 - val_accuracy: 0.3233\n",
            "Epoch 75/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3885 - accuracy: 0.3248 - val_loss: 2.4208 - val_accuracy: 0.3254\n",
            "Epoch 76/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3786 - accuracy: 0.3256 - val_loss: 2.4139 - val_accuracy: 0.3278\n",
            "Epoch 77/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3713 - accuracy: 0.3307 - val_loss: 2.4069 - val_accuracy: 0.3305\n",
            "Epoch 78/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3607 - accuracy: 0.3387 - val_loss: 2.4001 - val_accuracy: 0.3311\n",
            "Epoch 79/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3554 - accuracy: 0.3357 - val_loss: 2.3931 - val_accuracy: 0.3332\n",
            "Epoch 80/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.3471 - accuracy: 0.3405 - val_loss: 2.3863 - val_accuracy: 0.3344\n",
            "Epoch 81/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.3384 - accuracy: 0.3363 - val_loss: 2.3793 - val_accuracy: 0.3359\n",
            "Epoch 82/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3324 - accuracy: 0.3391 - val_loss: 2.3725 - val_accuracy: 0.3380\n",
            "Epoch 83/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3264 - accuracy: 0.3429 - val_loss: 2.3657 - val_accuracy: 0.3389\n",
            "Epoch 84/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3198 - accuracy: 0.3489 - val_loss: 2.3590 - val_accuracy: 0.3401\n",
            "Epoch 85/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3055 - accuracy: 0.3474 - val_loss: 2.3523 - val_accuracy: 0.3422\n",
            "Epoch 86/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.3008 - accuracy: 0.3521 - val_loss: 2.3456 - val_accuracy: 0.3464\n",
            "Epoch 87/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2977 - accuracy: 0.3503 - val_loss: 2.3389 - val_accuracy: 0.3479\n",
            "Epoch 88/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2841 - accuracy: 0.3532 - val_loss: 2.3321 - val_accuracy: 0.3509\n",
            "Epoch 89/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2823 - accuracy: 0.3625 - val_loss: 2.3253 - val_accuracy: 0.3512\n",
            "Epoch 90/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.2716 - accuracy: 0.3624 - val_loss: 2.3187 - val_accuracy: 0.3536\n",
            "Epoch 91/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2654 - accuracy: 0.3609 - val_loss: 2.3120 - val_accuracy: 0.3542\n",
            "Epoch 92/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.2550 - accuracy: 0.3602 - val_loss: 2.3054 - val_accuracy: 0.3569\n",
            "Epoch 93/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2513 - accuracy: 0.3631 - val_loss: 2.2989 - val_accuracy: 0.3596\n",
            "Epoch 94/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2448 - accuracy: 0.3707 - val_loss: 2.2921 - val_accuracy: 0.3611\n",
            "Epoch 95/100\n",
            "417/417 [==============================] - 6s 14ms/step - loss: 2.2363 - accuracy: 0.3699 - val_loss: 2.2857 - val_accuracy: 0.3626\n",
            "Epoch 96/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2306 - accuracy: 0.3715 - val_loss: 2.2791 - val_accuracy: 0.3629\n",
            "Epoch 97/100\n",
            "417/417 [==============================] - 5s 13ms/step - loss: 2.2261 - accuracy: 0.3701 - val_loss: 2.2727 - val_accuracy: 0.3659\n",
            "Epoch 98/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2127 - accuracy: 0.3737 - val_loss: 2.2661 - val_accuracy: 0.3662\n",
            "Epoch 99/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.2090 - accuracy: 0.3760 - val_loss: 2.2598 - val_accuracy: 0.3674\n",
            "Epoch 100/100\n",
            "417/417 [==============================] - 6s 13ms/step - loss: 2.1974 - accuracy: 0.3777 - val_loss: 2.2534 - val_accuracy: 0.3695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Also obviously, Highest Accuracy in Deep Learning Achieved at Unigrams using Fully Connected Layers "
      ],
      "metadata": {
        "id": "VL9_BTj4j6hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_model.save('pre-trained.h5')"
      ],
      "metadata": {
        "id": "jHEgcLs27oUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence Text"
      ],
      "metadata": {
        "id": "cZ7DrRdjoaMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_data = pd.read_csv('seq_data.csv')"
      ],
      "metadata": {
        "id": "gsypVPAXxLW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del seq_data['Unnamed: 0']"
      ],
      "metadata": {
        "id": "e3JtdBhLgh2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(seq_data, labels,test_size=0.2)\n",
        "print('Training Data:', X_train.shape[0])\n",
        "print('Test Data:', X_test.shape[0])"
      ],
      "metadata": {
        "id": "rdO1h9v5gGpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08efbd4-c899-4dba-dabd-ae58e44898bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: 16666\n",
            "Test Data: 4167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqdata_model = Sequential()\n",
        "seqdata_model.add(Dense(128, input_shape=((seq_data.shape)[1],), activation='tanh'))\n",
        "seqdata_model.add(Dropout(0.5))\n",
        "seqdata_model.add(Dense(64, activation='tanh'))\n",
        "seqdata_model.add(Dropout(0.5))\n",
        "seqdata_model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "sgd = SGD(learning_rate=0.001)\n",
        "seqdata_model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model \n",
        "hist = seqdata_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "026QNQl0an9T",
        "outputId": "fca7d955-80e1-4090-a61b-ed486485d235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "417/417 [==============================] - 2s 3ms/step - loss: 3.6158 - accuracy: 0.0533 - val_loss: 3.0761 - val_accuracy: 0.0663\n",
            "Epoch 2/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.5344 - accuracy: 0.0626 - val_loss: 3.0446 - val_accuracy: 0.0672\n",
            "Epoch 3/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.4852 - accuracy: 0.0622 - val_loss: 3.0304 - val_accuracy: 0.0612\n",
            "Epoch 4/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.4491 - accuracy: 0.0642 - val_loss: 2.9981 - val_accuracy: 0.0615\n",
            "Epoch 5/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.4232 - accuracy: 0.0645 - val_loss: 2.9922 - val_accuracy: 0.0696\n",
            "Epoch 6/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.3794 - accuracy: 0.0613 - val_loss: 2.9868 - val_accuracy: 0.0705\n",
            "Epoch 7/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.3610 - accuracy: 0.0632 - val_loss: 2.9746 - val_accuracy: 0.0690\n",
            "Epoch 8/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.3416 - accuracy: 0.0633 - val_loss: 2.9700 - val_accuracy: 0.0639\n",
            "Epoch 9/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.2897 - accuracy: 0.0667 - val_loss: 2.9585 - val_accuracy: 0.0669\n",
            "Epoch 10/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.2937 - accuracy: 0.0640 - val_loss: 2.9399 - val_accuracy: 0.0651\n",
            "Epoch 11/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.2510 - accuracy: 0.0635 - val_loss: 2.9391 - val_accuracy: 0.0705\n",
            "Epoch 12/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.2421 - accuracy: 0.0634 - val_loss: 2.9329 - val_accuracy: 0.0720\n",
            "Epoch 13/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.2295 - accuracy: 0.0641 - val_loss: 2.9213 - val_accuracy: 0.0756\n",
            "Epoch 14/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.2132 - accuracy: 0.0608 - val_loss: 2.9141 - val_accuracy: 0.0744\n",
            "Epoch 15/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.1772 - accuracy: 0.0667 - val_loss: 2.9077 - val_accuracy: 0.0756\n",
            "Epoch 16/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.1714 - accuracy: 0.0647 - val_loss: 2.9051 - val_accuracy: 0.0774\n",
            "Epoch 17/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.1723 - accuracy: 0.0629 - val_loss: 2.8973 - val_accuracy: 0.0813\n",
            "Epoch 18/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.1484 - accuracy: 0.0680 - val_loss: 2.8998 - val_accuracy: 0.0801\n",
            "Epoch 19/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.1363 - accuracy: 0.0650 - val_loss: 2.8980 - val_accuracy: 0.0765\n",
            "Epoch 20/20\n",
            "417/417 [==============================] - 1s 2ms/step - loss: 3.1223 - accuracy: 0.0640 - val_loss: 2.8969 - val_accuracy: 0.0744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=100\n",
        "\n",
        "model=Sequential()\n",
        "model.add(layers.Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=(X_train.shape)[1]))\n",
        "\n",
        "model.add(layers.LSTM(64))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(18, activation='relu'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "L1HUeLhn7ohW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=seqdata_model.fit(X_train,y_train, epochs=20, batch_size=128, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "id": "-dmUZfY6rcau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2b2114-bebb-42c2-c712-3feaece9783c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "45/45 [==============================] - 16s 233ms/step - loss: 6.0339 - accuracy: 0.0516 - val_loss: 5.2582 - val_accuracy: 0.0597\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 10s 225ms/step - loss: 5.4072 - accuracy: 0.0618 - val_loss: 5.1338 - val_accuracy: 0.0569\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 5.5890 - accuracy: 0.0700 - val_loss: 5.3575 - val_accuracy: 0.0535\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 10s 217ms/step - loss: 5.5495 - accuracy: 0.0580 - val_loss: 5.8217 - val_accuracy: 0.0590\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 5.6451 - accuracy: 0.0611 - val_loss: 5.4243 - val_accuracy: 0.0486\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 10s 219ms/step - loss: 5.6216 - accuracy: 0.0576 - val_loss: 5.3177 - val_accuracy: 0.0486\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 5.3668 - accuracy: 0.0762 - val_loss: 5.7307 - val_accuracy: 0.0542\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 5.6933 - accuracy: 0.0738 - val_loss: 6.2138 - val_accuracy: 0.0493\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 5.7454 - accuracy: 0.0573 - val_loss: 5.4016 - val_accuracy: 0.0493\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 10s 219ms/step - loss: 5.4187 - accuracy: 0.0601 - val_loss: 6.8691 - val_accuracy: 0.0486\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 10s 225ms/step - loss: 5.4737 - accuracy: 0.0602 - val_loss: 5.9222 - val_accuracy: 0.0486\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 10s 221ms/step - loss: 5.5830 - accuracy: 0.0910 - val_loss: 6.8107 - val_accuracy: 0.0542\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 10s 229ms/step - loss: 5.8820 - accuracy: 0.0865 - val_loss: 7.3223 - val_accuracy: 0.0653\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 10s 221ms/step - loss: 5.3610 - accuracy: 0.1333 - val_loss: 6.6573 - val_accuracy: 0.0604\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 5.8358 - accuracy: 0.0755 - val_loss: 6.5428 - val_accuracy: 0.0688\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 10s 220ms/step - loss: 5.8206 - accuracy: 0.0922 - val_loss: 2.8963 - val_accuracy: 0.0639\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 10s 216ms/step - loss: 2.8930 - accuracy: 0.0580 - val_loss: 2.8904 - val_accuracy: 0.0639\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 11s 239ms/step - loss: 2.8904 - accuracy: 0.0573 - val_loss: 2.8904 - val_accuracy: 0.0639\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 2.8904 - accuracy: 0.0573 - val_loss: 2.8904 - val_accuracy: 0.0639\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 10s 218ms/step - loss: 2.8899 - accuracy: 0.0575 - val_loss: 2.8904 - val_accuracy: 0.0639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "svm = LinearSVC(max_iter=300, multi_class='ovr')\n",
        "svm = svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "print('Accuracy : ', svm.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "id": "LitwK0umh0ya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9552280e-7bd8-4c73-ea83-83c1f521e838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.0650347972162227\n",
            "Precision of all classes:  [0.08152174 0.         0.05952381 0.06666667 0.         0.03921569\n",
            " 0.04518072 0.02631579 0.16666667 0.         0.1        0.\n",
            " 0.05555556 0.06741573 0.         0.066233   0.08510638 0.06038647]\n",
            "Recall of all classes:  [0.11749347 0.         0.04032258 0.04621849 0.         0.0456621\n",
            " 0.06355932 0.01777778 0.075      0.         0.00420168 0.\n",
            " 0.01702128 0.05063291 0.         0.4534413  0.0167364  0.09578544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LRC = LogisticRegression()\n",
        "LRC = LRC.fit(X_train, y_train)\n",
        "\n",
        "y_pred = LRC.predict(X_test)\n",
        "\n",
        "print('Accuracy : ', LRC.score(X_test, y_test))\n",
        "print(\"Precision of all classes: \", precision_score(y_test, y_pred, average=None))\n",
        "print(\"Recall of all classes: \", recall_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "id": "GDQHQd-i2kWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497360c0-0078-4e47-f359-d04321ab8cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.08999280057595392\n",
            "Precision of all classes:  [0.09059745 0.         0.10714286 0.04081633 0.         0.13829787\n",
            " 0.12676056 0.2        0.15777262 0.0506156  0.07142857 0.03448276\n",
            " 0.05789474 0.         0.         0.07352941 0.06930693 0.05825243]\n",
            "Recall of all classes:  [0.48302872 0.         0.01209677 0.00840336 0.         0.17808219\n",
            " 0.03813559 0.00444444 0.28333333 0.17619048 0.00420168 0.00390625\n",
            " 0.04680851 0.         0.         0.02024291 0.0292887  0.02298851]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Findings\n",
        "\n",
        "### The scores are too low compared to models that are usable in real world due to the slow fetching of tweets as decribed in the presentation, but this is just a demo of Arabic language preprocessing and modelling.\n",
        "\n",
        "### The highest accuracies are achieved at unigrams whether in machine or deep learning while it should not be and the best should be in trigrams, but after thinking about the reason, I thought about that is due to compound verbs (e.g. Carry out, catch up, look for, ...etc.) that is occurring too much in English while it's not occuring at the same familiarity in Arabic language so, the best N-Gram model in Arabic text processing is Uni-Grams \n",
        "\n",
        "### Proof: To make sure of the efficiency of the model that can achieve high scores if there's a big dataset to be trained on the same preprocesing and modelling technique and changing some hyperparamters to be compatible with modelling of this dataset, This approach is found in proof_of_efficieny.ipynb , The scores in both Machine Learning Algorithms ~= 91 % and in Deep Learning Fully Connected Network, Accuracy is ~= 93 %  \n",
        "\n",
        "\n",
        "### Finally, We saved the highest scores models in machine and deep learning to be deployed and tested by FAST API "
      ],
      "metadata": {
        "id": "dSLiLLQPckV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hhC9uMfUfXYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}